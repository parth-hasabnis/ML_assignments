{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import time\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_absolute_error, roc_auc_score, confusion_matrix\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3tTZ2ju6E_jX",
        "outputId": "c226dc01-1366-4bc5-bdbd-e8032b84477a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KEDVhepoS_IU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "PATH = \"/content/drive/MyDrive/Real Douments/MS Purdue/Spring 23/ML/train \"\n",
        "labels = pd.read_csv(os.path.join(PATH, \"train_small.csv\"))\n",
        "encodings = pd.read_csv(os.path.join(PATH, \"category.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uJYxBPJrU7gj",
        "outputId": "68fb3c70-749e-433c-a3f1-a9337fc828bd"
      },
      "outputs": [],
      "source": [
        "encodings.rename(columns={'Unnamed: 0': 'Label'}, inplace=True)\n",
        "encodings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0x1aQl_VTuz"
      },
      "outputs": [],
      "source": [
        "labels = labels.merge(encodings, how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fzgt6IvNWIkO",
        "outputId": "5d05ece5-9bac-4fd2-b07f-eb01122f37c4"
      },
      "outputs": [],
      "source": [
        "labels['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "g1nl9Qh8fZ8v",
        "outputId": "dafcd42f-49ea-444f-81c3-931002fb200b"
      },
      "outputs": [],
      "source": [
        "labels.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_c4sZSJe_Q3"
      },
      "outputs": [],
      "source": [
        "class CustomTrainDataset(Dataset):\n",
        "    def __init__(self, paths, labels, transform):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        name = self.paths[idx]\n",
        "        img = Image.open(f'{name}')\n",
        "        img = img.convert(\"RGB\")\n",
        "        img = np.array(img)\n",
        "        img = img.astype(\"float32\")\n",
        "        img /= 255.\n",
        "\n",
        "        transformed = self.transform(image=img)\n",
        "        img = transformed['image']\n",
        "        img = img.transpose(2,0,1).astype('float32')\n",
        "        labels = self.labels[idx]\n",
        "        return img, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZVLfv1Tfm_r"
      },
      "outputs": [],
      "source": [
        "def train_transform():\n",
        "    return A.Compose([\n",
        "        A.HorizontalFlip(),\n",
        "            A.OneOf([\n",
        "                A.RandomContrast(),\n",
        "                A.RandomGamma(),\n",
        "                A.RandomBrightness(),\n",
        "                ], p=0.3),\n",
        "            A.OneOf([\n",
        "                A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
        "                A.GridDistortion(),\n",
        "                A.OpticalDistortion(distort_limit=2, shift_limit=0.5),  \n",
        "                ], p=0.3),\n",
        "            A.ShiftScaleRotate(p=0.2),\n",
        "            A.Resize(256,256,always_apply=True),\n",
        "    ],p=1.)\n",
        "\n",
        "def val_transform():\n",
        "    return A.Compose([\n",
        "        A.Resize(256,256,always_apply=True),\n",
        "    ],p=1.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jCq45t8NfyWw",
        "outputId": "7615b5fa-bfa7-4222-f6ae-a0814290bf7d"
      },
      "outputs": [],
      "source": [
        "#/content/drive/MyDrive/Real Douments/MS Purdue/Spring 23/ML/train /train_small\n",
        "labels['File Name'] = PATH + \"/train_small/\" + labels['File Name']\n",
        "PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4Fg1gACmhZh"
      },
      "outputs": [],
      "source": [
        "target_df = pd.get_dummies(labels.Label)\n",
        "targets = target_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUkh-P3HR6FM",
        "outputId": "b7b4554a-aabb-41fe-d12e-72c07d6d1518"
      },
      "outputs": [],
      "source": [
        "labels['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VrFynh9EmsFg",
        "outputId": "e9c05770-b8f4-4023-a966-8989670c3d60"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm9Ib3Jtg_8w"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def prepare_train_valid_dataloader(df):\n",
        "    train_paths, val_paths, train_labels, val_labels = train_test_split(df['Filename'], df['Label']) \n",
        "    train_ds = CustomTrainDataset(train_paths, train_labels, train_transform)\n",
        "    val_ds = CustomTrainDataset(val_paths, val_labels, val_transform)\n",
        "    train_loader = DataLoader(train_ds, batch_size=128, pin_memory=True, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_ds, batch_size=64, pin_memory=True, shuffle=False, num_workers=4)\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuvGf-U4hMR-"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RIGg6KMhQy1"
      },
      "outputs": [],
      "source": [
        "class ImageRecgoModel(nn.Module):\n",
        "    def __init__(self, n_labels):\n",
        "        super(ImageRecgoModel, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(num_ftrs, 100)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwvMgJSZhXnw"
      },
      "outputs": [],
      "source": [
        "def Loss_fn(images, targets, model, device):\n",
        "    model.to(device)\n",
        "    images = images.to(device)\n",
        "    targets = targets.to(device)\n",
        "    outputs = model(images)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    loss = criterion(outputs, targets)\n",
        "    return loss, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNpZ9vznhb-5"
      },
      "outputs": [],
      "source": [
        "def train(epoch, model, device, optimizer, scheduler, trainloader):\n",
        "    model.train()\n",
        "    t = time.time()\n",
        "    total_loss = 0\n",
        "    total_targets = []\n",
        "    total_outputs = []\n",
        "    for step, (images, targets) in enumerate(trainloader):\n",
        "        loss, outputs = Loss_fn(images, targets, model, device)\n",
        "        loss.backward()\n",
        "        targets = targets.detach().cpu().numpy()\n",
        "        outputs = outputs.detach().cpu().numpy()\n",
        "        targets = targets.argmax(axis=1)\n",
        "        outputs = outputs.argmax(axis=1)\n",
        "        total_targets.extend(targets)\n",
        "        total_outputs.extend(outputs)\n",
        "        if ((step+1)%4==0 or (step+1)==len(trainloader)):\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "        loss = loss.detach().item()\n",
        "        total_loss += loss\n",
        "        if ((step+1)%10==0 or (step+1)==len(trainloader)):\n",
        "            print(\n",
        "                    f'epoch {epoch} train step {step+1}/{len(trainloader)}, ' + \\\n",
        "                    f'loss: {total_loss/len(trainloader):.4f}, ' + \\\n",
        "                    f'time: {(time.time() - t):.4f}', end= '\\r' if (step + 1) != len(trainloader) else '\\n'\n",
        "                )\n",
        "    accuracy = accuracy_score(total_targets, total_outputs)\n",
        "    print(f'Train Accuracy: {accuracy}')\n",
        "    return total_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhVxyIzhvU8"
      },
      "outputs": [],
      "source": [
        "def validate(epoch, model, device, optimizer, scheduler, validloader):\n",
        "    model.eval()\n",
        "    t = time.time()\n",
        "    total_loss = 0\n",
        "    total_targets = []\n",
        "    total_outputs = []\n",
        "    for step, (images, targets) in enumerate(validloader):\n",
        "        loss, outputs = Loss_fn(images, targets, model, device)\n",
        "        targets = targets.detach().cpu().numpy()\n",
        "        outputs = outputs.detach().cpu().numpy()\n",
        "        targets = targets.argmax(axis=1)\n",
        "        outputs = outputs.argmax(axis=1)\n",
        "        total_targets.extend(targets)\n",
        "        total_outputs.extend(outputs)\n",
        "        loss = loss.detach().item()\n",
        "        total_loss += loss\n",
        "        if ((step+1)%4==0 or (step+1)==len(validloader)):\n",
        "            scheduler.step(total_loss/len(validloader))\n",
        "        if ((step+1)%10==0 or (step+1)==len(validloader)):\n",
        "            print(\n",
        "                    f'epoch {epoch} val step {step+1}/{len(validloader)}, ' + \\\n",
        "                    f'loss: {total_loss/len(validloader):.4f}, ' + \\\n",
        "                    f'time: {(time.time() - t):.4f}', end= '\\r' if (step + 1) != len(validloader) else '\\n'\n",
        "                )\n",
        "            \n",
        "    accuracy = accuracy_score(total_targets, total_outputs)\n",
        "    cm = confusion_matrix(total_targets, total_outputs)\n",
        "    print(f'Validation Accuracy: {accuracy}')\n",
        "    return total_loss, accuracy, cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TkdTQ6d5iPg5",
        "outputId": "3fe01ab7-4a05-4c6a-dee8-02f36b78d9bf"
      },
      "outputs": [],
      "source": [
        "save_path = PATH + \"/Models/\"\n",
        "latest_path = \"/content/drive/MyDrive/Real Douments/MS Purdue/Spring 23/ML/train /Models/Best_model.pth\"\n",
        "\n",
        "trainloader, validloader = prepare_train_valid_dataloader(labels)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ImageRecgoModel(n_labels=100).to(device)\n",
        "\n",
        "# LOad state dict\n",
        "model.load_state_dict(torch.load(latest_path))\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.1, step_size=1)\n",
        "num_epochs = 20\n",
        "best_acc = 0\n",
        "history = {}\n",
        "history['loss'] = []\n",
        "history['val_loss'] = []\n",
        "history['accuracy'] = []\n",
        "history['val_accuracy'] = []\n",
        "best_val_acc = 0\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy = train(epoch, model, device, optimizer, scheduler, trainloader)\n",
        "    with torch.no_grad():\n",
        "        val_loss, val_accuracy, cm = validate(epoch, model, device, optimizer, scheduler, validloader)\n",
        "    if val_accuracy>best_acc:\n",
        "        torch.save(model.state_dict(),save_path + 'Best_model.pth')\n",
        "    history['loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['accuracy'].append(train_accuracy)\n",
        "    history['val_accuracy'].append(val_accuracy)\n",
        "\n",
        "torch.save(model.state_dict(),save_path + 'Last_epoch_model.pth')\n",
        "\n",
        "\n",
        "if val_accuracy>best_val_acc:\n",
        "    torch.save(model.state_dict(),save_path +  'Best_model.pth')\n",
        "\n",
        "       "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
